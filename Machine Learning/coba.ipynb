{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a4c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR   : d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\n",
      "PROJECT_DIR: d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\\Fraud_Detectio\n",
      "TRAIN_DIR  : d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\\Fraud_Detectio\\train\n",
      "VAL_DIR    : d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\\Fraud_Detectio\\val\n",
      "TEST_DIR   : d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\\Fraud_Detectio\\test\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Import & konfigurasi dasar + cek GPU\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# --- Konfigurasi path dataset asli (TIDAK pakai cls_dataset) ---\n",
    "BASE_DIR    = os.getcwd()\n",
    "PROJECT_DIR = os.path.join(BASE_DIR, \"Fraud_Detectio\")\n",
    "\n",
    "TRAIN_DIR = os.path.join(PROJECT_DIR, \"train\")  # berisi folder \"0\"\n",
    "VAL_DIR   = os.path.join(PROJECT_DIR, \"val\")    # berisi folder 0,90,180,270\n",
    "TEST_DIR  = os.path.join(PROJECT_DIR, \"test\")   # berisi folder 0,90,180,270\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH  = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"BASE_DIR   :\", BASE_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
    "print(\"TRAIN_DIR  :\", TRAIN_DIR)\n",
    "print(\"VAL_DIR    :\", VAL_DIR)\n",
    "print(\"TEST_DIR   :\", TEST_DIR)\n",
    "\n",
    "# Seed biar eksperimen agak konsisten\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71045960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Helper tampilan & loader\n",
    "\n",
    "def show_image(img_bgr, title=None, size=(4, 4)):\n",
    "    if img_bgr is None:\n",
    "        print(\"Image is None\")\n",
    "        return\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_image_tf(path, label):\n",
    "    \"\"\"\n",
    "    Loader untuk val/test:\n",
    "    - path: string path\n",
    "    - label: 0 (fraud) atau 1 (valid)\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    # tidak dibagi 255 di sini; nanti ada Rescaling(1/255) di model\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, tf.reshape(label, (1,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43af6afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gambar base train/0 : 4825\n",
      "Contoh: ['d:\\\\Coolyeah-Ngoding\\\\PBL\\\\Four-Heavenly-Principle\\\\Machine Learning\\\\Fraud_Detectio\\\\train\\\\0\\\\103_jpg.rf.095a1043937fa300847e77a2bb26d77c_ktp_0.jpg', 'd:\\\\Coolyeah-Ngoding\\\\PBL\\\\Four-Heavenly-Principle\\\\Machine Learning\\\\Fraud_Detectio\\\\train\\\\0\\\\103_jpg.rf.164c8de4bbaf6855d630b1312b08c82b_ktp_0.jpg', 'd:\\\\Coolyeah-Ngoding\\\\PBL\\\\Four-Heavenly-Principle\\\\Machine Learning\\\\Fraud_Detectio\\\\train\\\\0\\\\103_jpg.rf.1ebeee8b2d5f896f697f98f27f65a092_ktp_0.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Kumpulkan path training base dari train/0\n",
    "\n",
    "train0_dir = os.path.join(TRAIN_DIR, \"0\")\n",
    "train0_paths = []\n",
    "\n",
    "for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "    train0_paths.extend(glob.glob(os.path.join(train0_dir, ext)))\n",
    "\n",
    "train0_paths = sorted(train0_paths)\n",
    "\n",
    "print(\"Total gambar base train/0 :\", len(train0_paths))\n",
    "if len(train0_paths) > 0:\n",
    "    print(\"Contoh:\", train0_paths[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba88fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\\Fraud_Detectio\\val\n",
      "  Total  : 1860\n",
      "  VALID  : 465\n",
      "  FRAUD  : 1395\n",
      "Root: d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\\Fraud_Detectio\\test\n",
      "  Total  : 936\n",
      "  VALID  : 234\n",
      "  FRAUD  : 702\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Kumpulkan path & label untuk VAL dan TEST\n",
    "\n",
    "def collect_split_from_root(root_dir):\n",
    "    \"\"\"\n",
    "    Ambil semua gambar dari root_dir/{0,90,180,270}\n",
    "    0   -> label 1 (VALID)\n",
    "    90/180/270 -> label 0 (FRAUD)\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    labels = []\n",
    "\n",
    "    def add_angle(angle, label):\n",
    "        d = os.path.join(root_dir, str(angle))\n",
    "        if not os.path.isdir(d):\n",
    "            return\n",
    "        all_files = []\n",
    "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "            all_files.extend(glob.glob(os.path.join(d, ext)))\n",
    "        for p in all_files:\n",
    "            paths.append(p)\n",
    "            labels.append(label)\n",
    "\n",
    "    # VALID\n",
    "    add_angle(0, 1.0)\n",
    "    # FRAUD (orientasi salah)\n",
    "    for ang in [90, 180, 270]:\n",
    "        add_angle(ang, 0.0)\n",
    "\n",
    "    paths = np.array(paths)\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "    print(f\"Root: {root_dir}\")\n",
    "    print(f\"  Total  : {len(paths)}\")\n",
    "    print(f\"  VALID  : {(labels == 1).sum()}\")\n",
    "    print(f\"  FRAUD  : {(labels == 0).sum()}\")\n",
    "    return paths, labels\n",
    "\n",
    "\n",
    "paths_val, labels_val   = collect_split_from_root(VAL_DIR)\n",
    "paths_test, labels_test = collect_split_from_root(TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b2fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Fungsi augmentasi untuk training generator\n",
    "\n",
    "def rotate_image(img_bgr, angle):\n",
    "    (h, w) = img_bgr.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(img_bgr, M, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "def random_brightness_contrast(img_bgr, brightness=0.2, contrast=0.2):\n",
    "    img = img_bgr.astype(np.float32) / 255.0\n",
    "    alpha = 1.0 + random.uniform(-contrast, contrast)\n",
    "    beta  = random.uniform(-brightness, brightness)\n",
    "    img = alpha * img + beta\n",
    "    img = np.clip(img, 0, 1)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def add_gaussian_noise(img_bgr, std=10.0):\n",
    "    noise = np.random.normal(0, std, img_bgr.shape).astype(np.float32)\n",
    "    noisy = img_bgr.astype(np.float32) + noise\n",
    "    noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "    return noisy\n",
    "\n",
    "def random_crop_and_resize(img_bgr, crop_factor=(0.5, 0.9)):\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    min_cf, max_cf = crop_factor\n",
    "    cf = random.uniform(min_cf, max_cf)\n",
    "    new_h, new_w = int(h * cf), int(w * cf)\n",
    "    if new_h <= 0 or new_w <= 0:\n",
    "        return cv2.resize(img_bgr, (w, h))\n",
    "    y = random.randint(0, h - new_h)\n",
    "    x = random.randint(0, w - new_w)\n",
    "    cropped = img_bgr[y:y+new_h, x:x+new_w]\n",
    "    resized = cv2.resize(cropped, (w, h))\n",
    "    return resized\n",
    "\n",
    "def add_letterbox_fraud(img_bgr, scale=0.6, bg_color=0):\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    nh, nw = int(h*scale), int(w*scale)\n",
    "    resized = cv2.resize(img_bgr, (nw, nh))\n",
    "    canvas = np.full_like(img_bgr, bg_color)\n",
    "    y = (h - nh)//2\n",
    "    x = (w - nw)//2\n",
    "    canvas[y:y+nh, x:x+nw] = resized\n",
    "    return canvas\n",
    "\n",
    "# --- Tampering (edit isi) ---\n",
    "\n",
    "def block_nik_area(img_bgr):\n",
    "    img = img_bgr.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1 = int(0.05 * w), int(0.12 * h)\n",
    "    x2, y2 = int(0.95 * w), int(0.25 * h)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 0), thickness=-1)\n",
    "    return img\n",
    "\n",
    "def big_text_area_blur(img_bgr):\n",
    "    img = img_bgr.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1 = int(0.05 * w), int(0.20 * h)\n",
    "    x2, y2 = int(0.95 * w), int(0.75 * h)\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    if roi.size > 0:\n",
    "        roi = cv2.GaussianBlur(roi, (31, 31), 0)\n",
    "        img[y1:y2, x1:x2] = roi\n",
    "    return img\n",
    "\n",
    "def big_white_patch(img_bgr):\n",
    "    img = img_bgr.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1 = int(0.05 * w), int(0.20 * h)\n",
    "    x2, y2 = int(0.95 * w), int(0.75 * h)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 255), thickness=-1)\n",
    "    return img\n",
    "\n",
    "def random_text_overlay(img_bgr):\n",
    "    img = img_bgr.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    text = \"EDITED\"\n",
    "    org = (int(0.1 * w), int(0.5 * h))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1.0\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 2\n",
    "    cv2.putText(img, text, org, font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def random_face_blur(img_bgr):\n",
    "    img = img_bgr.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1 = int(0.55 * w), int(0.25 * h)\n",
    "    x2, y2 = int(0.9  * w), int(0.75 * h)\n",
    "    roi = img[y1:y2, x1:x2]\n",
    "    if roi.size > 0:\n",
    "        roi = cv2.GaussianBlur(roi, (31, 31), 0)\n",
    "        img[y1:y2, x1:x2] = roi\n",
    "    return img\n",
    "\n",
    "def strong_letterbox_meme(img_bgr):\n",
    "    img = img_bgr.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    scale = 0.5\n",
    "    nh, nw = int(h * scale), int(w * scale)\n",
    "    resized = cv2.resize(img_bgr, (nw, nh))\n",
    "    canvas = np.ones_like(img_bgr) * 255  # putih\n",
    "    y = (h - nh)//2\n",
    "    x = (w - nw)//2\n",
    "    canvas[y:y+nh, x:x+nw] = resized\n",
    "    return canvas\n",
    "\n",
    "# --- Wrapper augmentasi VALID & FRAUD ---\n",
    "\n",
    "def make_valid_aug(img_bgr):\n",
    "    img = img_bgr.copy()\n",
    "    # sedikit jitter tapi tetap \"rapih\"\n",
    "    if random.random() < 0.7:\n",
    "        img = random_brightness_contrast(img, 0.15, 0.15)\n",
    "    if random.random() < 0.4:\n",
    "        img = add_gaussian_noise(img, std=5.0)\n",
    "    if random.random() < 0.3:\n",
    "        img = random_crop_and_resize(img, crop_factor=(0.9, 0.98))\n",
    "    return img\n",
    "\n",
    "def make_fraud_aug(img_bgr):\n",
    "    \"\"\"\n",
    "    Fraud bisa:\n",
    "    - orientasi salah (rotasi, crop parah, letterbox)\n",
    "    - tampering 0° (blur teks besar, patch putih, blur wajah, dll.)\n",
    "    \"\"\"\n",
    "    img = img_bgr.copy()\n",
    "    \n",
    "    fraud_mode = random.choice([\"orientation\", \"tampering\"])\n",
    "\n",
    "    if fraud_mode == \"orientation\":\n",
    "        ftype = random.choice([\"rot_90\", \"rot_180\", \"rot_270\",\n",
    "                               \"tilt_small\", \"crop\", \"letterbox\"])\n",
    "        if ftype == \"rot_90\":\n",
    "            img = rotate_image(img, 90)\n",
    "        elif ftype == \"rot_180\":\n",
    "            img = rotate_image(img, 180)\n",
    "        elif ftype == \"rot_270\":\n",
    "            img = rotate_image(img, 270)\n",
    "        elif ftype == \"tilt_small\":\n",
    "            angle = random.choice([-30, -20, -15, 15, 20, 30])\n",
    "            img = rotate_image(img, angle)\n",
    "        elif ftype == \"crop\":\n",
    "            img = random_crop_and_resize(img, crop_factor=(0.4, 0.75))\n",
    "        elif ftype == \"letterbox\":\n",
    "            img = add_letterbox_fraud(img, scale=0.6, bg_color=0)\n",
    "    else:\n",
    "        ftype = random.choice([\n",
    "            \"block_nik\",\n",
    "            \"big_text_blur\",\n",
    "            \"big_white_patch\",\n",
    "            \"face_blur\",\n",
    "            \"text_overlay\",\n",
    "            \"meme_letterbox\"\n",
    "        ])\n",
    "        if ftype == \"block_nik\":\n",
    "            img = block_nik_area(img)\n",
    "        elif ftype == \"big_text_blur\":\n",
    "            img = big_text_area_blur(img)\n",
    "        elif ftype == \"big_white_patch\":\n",
    "            img = big_white_patch(img)\n",
    "        elif ftype == \"face_blur\":\n",
    "            img = random_face_blur(img)\n",
    "        elif ftype == \"text_overlay\":\n",
    "            img = random_text_overlay(img)\n",
    "        elif ftype == \"meme_letterbox\":\n",
    "            img = strong_letterbox_meme(img)\n",
    "\n",
    "    # Noise/brightness tambahan\n",
    "    if random.random() < 0.6:\n",
    "        img = random_brightness_contrast(img, 0.2, 0.2)\n",
    "    if random.random() < 0.6:\n",
    "        img = add_gaussian_noise(img, std=8.0)\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546ef965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Keras Sequence untuk training (augment on-the-fly)\n",
    "\n",
    "class KTPTrainSequence(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Generator untuk training:\n",
    "    - Sumber: train0_paths (0°)\n",
    "    - Setiap batch, kita buat campuran:\n",
    "        label 1 (VALID) : image + make_valid_aug\n",
    "        label 0 (FRAUD) : image + make_fraud_aug (rotasi/tampering)\n",
    "    \"\"\"\n",
    "    def __init__(self, img_paths, batch_size=BATCH_SIZE, steps_per_epoch=1000, fraud_ratio=0.5):\n",
    "        self.img_paths = list(img_paths)\n",
    "        self.batch_size = batch_size\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.fraud_ratio = fraud_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps_per_epoch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = np.zeros((self.batch_size, IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.float32)\n",
    "        batch_y = np.zeros((self.batch_size, 1), dtype=np.float32)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            path = random.choice(self.img_paths)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                # fallback: kalau gagal baca, pakai gambar random lain\n",
    "                path2 = random.choice(self.img_paths)\n",
    "                img = cv2.imread(path2)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "            # tentukan valid/fraud\n",
    "            if random.random() < self.fraud_ratio:\n",
    "                # FRAUD\n",
    "                img_aug = make_fraud_aug(img)\n",
    "                label = 0.0\n",
    "            else:\n",
    "                # VALID\n",
    "                img_aug = make_valid_aug(img)\n",
    "                label = 1.0\n",
    "\n",
    "            batch_x[i] = img_aug.astype(np.float32)\n",
    "            batch_y[i, 0] = label\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "\n",
    "# tentukan steps_per_epoch (boleh disesuaikan)\n",
    "STEPS_PER_EPOCH = 200  # misal 200 batch per epoch\n",
    "\n",
    "train_gen = KTPTrainSequence(\n",
    "    train0_paths,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    fraud_ratio=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ca7a61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_ds : <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "test_ds: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Buat tf.data.Dataset untuk val & test (tanpa augment)\n",
    "\n",
    "def make_dataset(paths, labels, batch_size=BATCH_SIZE, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(paths), seed=SEED)\n",
    "    ds = ds.map(load_image_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "val_ds  = make_dataset(paths_val,  labels_val,  shuffle=False)\n",
    "test_ds = make_dataset(paths_test, labels_test, shuffle=False)\n",
    "\n",
    "print(\"val_ds :\", val_ds)\n",
    "print(\"test_ds:\", test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e29f377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m12,845,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,233,985</span> (50.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,233,985\u001b[0m (50.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,233,985</span> (50.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,233,985\u001b[0m (50.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Definisi model CNN (valid vs fraud)\n",
    "\n",
    "def build_ktp_fraud_cnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Rescaling(1./255),\n",
    "\n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')  # output = P(VALID)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_ktp_fraud_cnn()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1168180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafir\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.7410 - auc: 0.8194 - loss: 0.4892\n",
      "Epoch 1: val_loss improved from None to 1.43120, saving model to d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\\Fraud_Detectio\\saved_models\\ktp_fraud_cnn_tampering_v1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 523ms/step - accuracy: 0.8461 - auc: 0.9295 - loss: 0.3404 - val_accuracy: 0.5522 - val_auc: 0.5000 - val_loss: 1.4312\n",
      "Epoch 2/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.9528 - auc: 0.9900 - loss: 0.1303\n",
      "Epoch 2: val_loss did not improve from 1.43120\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 400ms/step - accuracy: 0.9577 - auc: 0.9921 - loss: 0.1152 - val_accuracy: 0.4683 - val_auc: 0.5000 - val_loss: 2.8949\n",
      "Epoch 3/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.9819 - auc: 0.9963 - loss: 0.0687\n",
      "Epoch 3: val_loss did not improve from 1.43120\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 375ms/step - accuracy: 0.9827 - auc: 0.9968 - loss: 0.0636 - val_accuracy: 0.4726 - val_auc: 0.5000 - val_loss: 3.4256\n",
      "Epoch 4/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - accuracy: 0.9842 - auc: 0.9979 - loss: 0.0509\n",
      "Epoch 4: val_loss did not improve from 1.43120\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 496ms/step - accuracy: 0.9841 - auc: 0.9978 - loss: 0.0519 - val_accuracy: 0.4823 - val_auc: 0.5000 - val_loss: 2.9616\n",
      "Epoch 5/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.9869 - auc: 0.9979 - loss: 0.0475\n",
      "Epoch 5: val_loss did not improve from 1.43120\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 411ms/step - accuracy: 0.9891 - auc: 0.9983 - loss: 0.0410 - val_accuracy: 0.4651 - val_auc: 0.5000 - val_loss: 4.7619\n",
      "Epoch 6/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.9902 - auc: 0.9995 - loss: 0.0299\n",
      "Epoch 6: val_loss did not improve from 1.43120\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 469ms/step - accuracy: 0.9911 - auc: 0.9993 - loss: 0.0292 - val_accuracy: 0.4737 - val_auc: 0.5000 - val_loss: 4.6070\n",
      "Model disimpan ke: d:\\Coolyeah-Ngoding\\PBL\\Four-Heavenly-Principle\\Machine Learning\\Fraud_Detectio\\saved_models\\ktp_fraud_cnn_tampering_v1.h5\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Compile & training\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "MODEL_SAVE_DIR = os.path.join(PROJECT_DIR, \"saved_models\")\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "MODEL_OUT_PATH = os.path.join(MODEL_SAVE_DIR, \"ktp_fraud_cnn_tampering_v1.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        MODEL_OUT_PATH,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "EPOCHS = 20  # bisa dinaikkan kalau belum overfitting\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"Model disimpan ke:\", MODEL_OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c1d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.5214 - auc: 0.5000 - loss: 1.3995 \n",
      "Test loss: 1.3995\n",
      "Test acc : 0.5214\n",
      "Test AUC : 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Evaluasi di test set\n",
    "\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_ds)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test acc : {test_acc:.4f}\")\n",
    "print(f\"Test AUC : {test_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
